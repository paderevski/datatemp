{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/paderevski/datatemp/blob/main/Songs.ipynb",
      "authorship_tag": "ABX9TyMh4KoxnqLxw0R1cRMnHTTP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paderevski/datatemp/blob/main/Songs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Song Genre"
      ],
      "metadata": {
        "id": "mtP511kDJJRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import os"
      ],
      "metadata": {
        "id": "ibsa461Rm9nj"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import librosa\n",
        "import librosa.display\n",
        "import IPython.display as ipd\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "QumSNUpwncEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PkmudKZEM5E"
      },
      "outputs": [],
      "source": [
        "cmd = \"tar xzf /content/drive/MyDrive/Colab/genres.tar.gz\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.system(cmd)"
      ],
      "metadata": {
        "id": "Nw8K1fZSnHfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"bird_songs_metadata.csv\")"
      ],
      "metadata": {
        "id": "ysa-725unnNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "LCwmBdHhqEZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# @title Category Distribution\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "df.groupby('name').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "id": "ShFWy6qAqzeM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title File Sizes\n",
        "\n",
        "import os\n",
        "import random\n",
        "\n",
        "wav_files_dir = 'wavfiles'\n",
        "wav_files = [f for f in os.listdir(wav_files_dir) if f.endswith('.wav')]\n",
        "\n",
        "# Select 10 random .wav files\n",
        "random_wav_files = random.sample(wav_files, min(10, len(wav_files)))\n",
        "\n",
        "for filename in random_wav_files:\n",
        "    filepath = os.path.join(wav_files_dir, filename)\n",
        "    try:\n",
        "        file_size = os.path.getsize(filepath)\n",
        "        print(f\"File: {filename}, Size: {file_size} bytes\")\n",
        "    except OSError as e:\n",
        "        print(f\"Error getting size of {filename}: {e}\")\n"
      ],
      "metadata": {
        "id": "EgHOQuWPrWt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Load audio data and labels\n",
        "import os\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "# Assuming 'df' and 'wav_files_dir' are defined from the previous code\n",
        "# ... (previous code to load the dataframe and directory)\n",
        "\n",
        "dataset = []\n",
        "for index, row in df.iterrows():\n",
        "    wav_file = os.path.join(wav_files_dir, row['filename'])\n",
        "    if os.path.exists(wav_file):\n",
        "        try:\n",
        "            y, sr = librosa.load(wav_file, sr=None) #Load with original sample rate\n",
        "            dataset.append({'X': y, 'Y': row['name']})\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {wav_file}: {e}\")\n",
        "    else:\n",
        "        print(f\"File not found: {wav_file}\")\n",
        "\n",
        "# Convert to numpy arrays for easier use\n",
        "X = np.array([item['X'] for item in dataset])\n",
        "Y = np.array([item['Y'] for item in dataset])\n",
        "\n",
        "# Now you have X (audio data) and Y (bird names) in numpy arrays.\n",
        "# You can further process and split these arrays for machine learning tasks.\n",
        "print(X.shape,Y.shape)\n"
      ],
      "metadata": {
        "id": "s-9qxjFMrvUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title save this X,Y to a file\n",
        "np.save('X.npy', X)\n",
        "np.save('Y.npy', Y)"
      ],
      "metadata": {
        "id": "SgabwL6UsJLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title load the file\n",
        "X = np.load('X.npy')\n",
        "Y = np.load('Y.npy')"
      ],
      "metadata": {
        "id": "_6tVN5VKu35k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "# Assuming X and Y are already loaded from the previous code\n",
        "# ... (previous code to load X and Y)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42) # Adjust test_size as needed\n",
        "\n",
        "# Encode the target variable (Y) using Label Encoding and One-Hot Encoding\n",
        "label_encoder = LabelEncoder()\n",
        "integer_encoded_Y_train = label_encoder.fit_transform(Y_train)\n",
        "integer_encoded_Y_test = label_encoder.transform(Y_test)\n",
        "\n",
        "onehot_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore') # sparse=False for dense array\n",
        "onehot_encoded_Y_train = onehot_encoder.fit_transform(integer_encoded_Y_train.reshape(-1, 1))\n",
        "onehot_encoded_Y_test = onehot_encoder.transform(integer_encoded_Y_test.reshape(-1, 1))\n",
        "\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"Y_train shape (one-hot encoded):\", onehot_encoded_Y_train.shape)\n",
        "print(\"Y_test shape (one-hot encoded):\", onehot_encoded_Y_test.shape)\n"
      ],
      "metadata": {
        "id": "3AJbWZW4swIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# Assuming X and Y are already loaded from the previous code\n",
        "# ... (previous code to load X and Y)\n",
        "\n",
        "# Select 3 random indices\n",
        "random_indices = random.sample(range(len(X)), 3)\n",
        "\n",
        "for i in random_indices:\n",
        "    plt.figure(figsize=(10, 4))  # Adjust figure size as needed\n",
        "    plt.plot(X[i])\n",
        "    plt.title(f\"Audio Data for Bird: {Y[i]}\") #added a title\n",
        "    plt.xlabel(\"Sample\") #added x axis label\n",
        "    plt.ylabel(\"Amplitude\") #added y axis label\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "rrEagR8qtFrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: ok now let's turn each bird call into MFCC data\n",
        "\n",
        "import librosa\n",
        "\n",
        "# Assuming X_train, X_test are already defined and loaded from previous code\n",
        "# ... (previous code to load X_train and X_test)\n",
        "\n",
        "def extract_mfccs(audio_data, n_mfcc=26, n_fft=2048, hop_length=512):\n",
        "    \"\"\"Extracts MFCCs from audio data.\"\"\"\n",
        "    mfccs = librosa.feature.mfcc(y=audio_data, sr=22050, n_mfcc=n_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
        "    # scale, adding vertical pixels to make a square image\n",
        "    mfccs = tf.image.resize(np.expand_dims(mfccs, axis=-1), [130, 130])\n",
        "    mfccs = tf.squeeze(mfccs)\n",
        "    mfccs = mfccs.numpy()\n",
        "\n",
        "    return mfccs\n",
        "\n",
        "# Example usage:\n",
        "X_train_mfccs = [extract_mfccs(x) for x in X_train]\n",
        "X_test_mfccs = [extract_mfccs(x) for x in X_test]\n",
        "\n"
      ],
      "metadata": {
        "id": "U6eosH88w4a-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_mfccs[0].shape"
      ],
      "metadata": {
        "id": "TNk5t5yY_BXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "librosa.display.specshow(X_train_mfccs[0], sr=22050, x_axis='time')\n",
        "plt.colorbar()\n",
        "plt.title('MFCCs for Bird: {}'.format(Y_train[0]))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KZ6A9Cq99e5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: plot 3 random MFCCs from X_train_mfccs and label with their Y value. Mkae a 2D heat map plot using all 13 MFCCs on the Y axis\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "import random\n",
        "\n",
        "# Select 3 random indices\n",
        "random_indices = random.sample(range(len(X_train_mfccs)), 3)\n",
        "\n",
        "for i in random_indices:\n",
        "    # Plot MFCCs\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    librosa.display.specshow(X_train_mfccs[i], sr=22050, x_axis='time')\n",
        "    plt.colorbar()\n",
        "    plt.title(f\"MFCCs for Bird: {Y_train[i]}\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "vgpAtr7azq8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mfcc = X_train_mfccs[0]"
      ],
      "metadata": {
        "id": "X5xnTcjV7DuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mfcc.shape"
      ],
      "metadata": {
        "id": "Ft9QpKeA7LRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import numpy as np\n",
        "\n",
        "# Assuming X_train_mfccs and onehot_encoded_Y_train are defined from the previous code\n",
        "# ... (previous code to load X_train_mfccs and onehot_encoded_Y_train)\n",
        "\n",
        "X_train_mfccs = np.array(X_train_mfccs)\n",
        "onehot_encoded_Y_train = np.array(onehot_encoded_Y_train)\n",
        "\n",
        "# Split the training data into training and validation sets\n",
        "X_train_final, X_val, Y_train_final, Y_val = train_test_split(\n",
        "    X_train_mfccs, onehot_encoded_Y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Reshape data for CNN input (assuming the shape is (number of samples, 130, 130, 1))\n",
        "X_train_final = X_train_final.reshape(-1, 130, 130, 1)\n",
        "X_val = X_val.reshape(-1, 130, 130, 1)\n",
        "\n",
        "\n",
        "# Define the CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(64, (5, 3), activation='relu', input_shape=(130, 130, 1), padding='same'),\n",
        "    Conv2D(64, (7, 7), activation='relu', padding = 'same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Conv2D(64, (5, 5), activation='relu', padding = 'same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(onehot_encoded_Y_train.shape[1], activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Define early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the model with validation data and early stopping\n",
        "history = model.fit(X_train_final, Y_train_final, epochs=50, batch_size=64,\n",
        "                    validation_data=(X_val, Y_val), callbacks=[early_stopping])\n",
        "\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_val, Y_val)\n",
        "print(f\"Validation Loss: {loss:.4f}\")\n",
        "print(f\"Validation Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "Nh5Xf3Ye116H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "bVMic02Y3E6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import random\n",
        "from scipy import signal  # Import scipy.signal\n",
        "z\n",
        "def augment_audio(audio_data, sr):\n",
        "    \"\"\"\n",
        "    Augments audio data by adjusting pitch, applying low-pass and high-pass filters randomly.\n",
        "    \"\"\"\n",
        "    augmented_data = audio_data.copy()\n",
        "\n",
        "    # Pitch shift\n",
        "    pitch_shift_factor = random.uniform(-0.2, 0.2)  # +/- 20% pitch shift\n",
        "    augmented_data = librosa.effects.pitch_shift(augmented_data, sr=sr, n_steps=pitch_shift_factor)\n",
        "\n",
        "    # Randomly apply low-pass or high-pass filters\n",
        "    if random.random() < 0.5:  # Apply with 50% probability\n",
        "        cutoff_freq_low = random.uniform(5000, 10000) #random cutoff frequency\n",
        "        augmented_data = apply_lowpass_filter(augmented_data, sr, cutoff_freq_low)\n",
        "\n",
        "    if random.random() < 0.5:  # Apply with 50% probability\n",
        "        cutoff_freq_high = random.uniform(500, 1000) #random cutoff frequency\n",
        "        augmented_data = apply_highpass_filter(augmented_data, sr, cutoff_freq_high)\n",
        "\n",
        "    return augmented_data\n",
        "\n",
        "def apply_lowpass_filter(audio, sr, cutoff_freq):\n",
        "    nyquist_freq = 0.5 * sr\n",
        "    normalized_cutoff = cutoff_freq / nyquist_freq\n",
        "    # Use scipy.signal.butter instead\n",
        "    b, a = signal.butter(4, normalized_cutoff, btype='lowpass')\n",
        "    filtered_audio = signal.filtfilt(b, a, audio)  # Use signal.filtfilt\n",
        "    return filtered_audio\n",
        "\n",
        "def apply_highpass_filter(audio, sr, cutoff_freq):\n",
        "    nyquist_freq = 0.5 * sr\n",
        "    normalized_cutoff = cutoff_freq / nyquist_freq\n",
        "    # Use scipy.signal.butter instead\n",
        "    b, a = signal.butter(4, normalized_cutoff, btype='highpass')\n",
        "    filtered_audio = signal.filtfilt(b, a, audio)  # Use signal.filtfilt\n",
        "    return filtered_audio\n",
        "\n",
        "# Example usage (assuming you have 'dataset' from your previous code)\n",
        "\n",
        "augmented_dataset = []\n",
        "for item in dataset:\n",
        "    augmented_audio_data = augment_audio(item['X'], 22050)  # Assuming a sample rate of 22050\n",
        "    augmented_dataset.append({'X': augmented_audio_data, 'Y': item['Y']})\n",
        "\n",
        "# Convert the augmented dataset to NumPy arrays\n",
        "augmented_X = np.array([item['X'] for item in augmented_dataset])\n",
        "augmented_Y = np.array([item['Y'] for item in augmented_dataset])\n",
        "\n",
        "# Now you can use 'augmented_X' and 'augmented_Y' for training your model\n",
        "print(\"Augmented data shapes:\", augmented_X.shape, augmented_Y.shape)"
      ],
      "metadata": {
        "id": "L8KcCrYh69pX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: add the augmented data to the original X_train\n",
        "\n",
        "# Combine original and augmented data\n",
        "X_train_combined = np.concatenate((X_train, augmented_X), axis=0)\n",
        "Y_train_combined = np.concatenate((Y_train, augmented_Y), axis=0)\n",
        "\n",
        "print(\"Combined training data shapes:\", X_train_combined.shape, Y_train_combined.shape)\n"
      ],
      "metadata": {
        "id": "IIVsoX-REsJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: now let's run the same MFCC filtering, rescaling and training from above, on this new augmented data set\n",
        "\n",
        "# Assuming X_train_combined and Y_train_combined are defined from the previous code\n",
        "# ... (previous code to create X_train_combined and Y_train_combined)\n",
        "\n",
        "# Encode the combined target variable\n",
        "label_encoder_combined = LabelEncoder()\n",
        "integer_encoded_Y_train_combined = label_encoder_combined.fit_transform(Y_train_combined)\n",
        "\n",
        "onehot_encoder_combined = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "onehot_encoded_Y_train_combined = onehot_encoder_combined.fit_transform(integer_encoded_Y_train_combined.reshape(-1, 1))\n",
        "\n",
        "# Extract MFCCs from the combined training data\n",
        "X_train_mfccs_combined = [extract_mfccs(x) for x in X_train_combined]\n",
        "X_test_mfccs_combined = [extract_mfccs(x) for x in X_test]\n",
        "\n",
        "\n",
        "X_train_mfccs_combined = np.array(X_train_mfccs_combined)\n",
        "X_test_mfccs_combined = np.array(X_test_mfccs_combined)\n",
        "onehot_encoded_Y_train_combined = np.array(onehot_encoded_Y_train_combined)\n",
        "onehot_encoded_Y_test = np.array(onehot_encoded_Y_test)\n",
        "\n",
        "\n",
        "# Reshape data for CNN input\n",
        "X_train_mfccs_combined = X_train_mfccs_combined.reshape(-1, 130, 130, 1)\n",
        "X_test_mfccs_combined = X_test_mfccs_combined.reshape(-1, 130, 130, 1)\n",
        "\n",
        "# Split the combined training data into training and validation sets\n",
        "X_train_final_combined, X_val_combined, Y_train_final_combined, Y_val_combined = train_test_split(\n",
        "    X_train_mfccs_combined, onehot_encoded_Y_train_combined, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define and compile the model (same as before)\n",
        "model_combined = model\n",
        "\n",
        "model_combined.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model with the combined data\n",
        "history_combined = model_combined.fit(X_train_final_combined, Y_train_final_combined, epochs=50, batch_size=64,\n",
        "                    validation_data=(X_val_combined, Y_val_combined), callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss_combined, accuracy_combined = model_combined.evaluate(X_test_mfccs_combined, onehot_encoded_Y_test, verbose=0)\n",
        "print(\"Test Loss:\", loss_combined)\n",
        "print(\"Test Accuracy:\", accuracy_combined)\n"
      ],
      "metadata": {
        "id": "C_YlF7w6GTSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: make a confusion chart heat map for the birds in the test set, using the best model in the previous cell\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Assuming model_combined and X_test_mfccs_combined are defined\n",
        "# ... (previous code to define and train model_combined)\n",
        "\n",
        "# Predict the classes for the test set\n",
        "Y_pred_prob = model_combined.predict(X_test_mfccs_combined)\n",
        "Y_pred = np.argmax(Y_pred_prob, axis=1)\n",
        "\n",
        "# Get the true classes for the test set\n",
        "Y_true = np.argmax(onehot_encoded_Y_test, axis=1)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(Y_true, Y_pred)\n",
        "\n",
        "# Plot the confusion matrix as a heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix for Bird Species Classification')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "68Z8heYoHHKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IvjqRhLFO53s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}